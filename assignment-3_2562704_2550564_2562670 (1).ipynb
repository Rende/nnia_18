{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment sheet 3: Numerical Computation and Prinicipal Component Analysis (Deadline: Nov 24, 23:59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set notebook to full width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Issues with Softmax $~$ (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture you were introduced to the softmax function which is used to generate probabilities corresponding to the output labels. Typically, the input to the softmax function is a vector of numerical values over the labels and the output is a vector(of same dimension as the input vector) of corresponding probabilities.\n",
    "**Softmax function is given by,** $~$\n",
    "$$Softmax(x)_i = \\frac{exp(x_i)}{\\sum_{j=1}^n exp(x_j)}$$\n",
    "\n",
    "**Numerical issues might occur when computing softmax functions on a computer which can perform computations\n",
    "only upto a certain precision.** [Suggested reading $-$ [chapter 4.1 of DeepLearningBook](http://www.deeplearningbook.org/contents/numerical.html)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$. Name these numerical issues and explain them. ($1$ points)\n",
    "\n",
    "> 1/1\n",
    "\n",
    "Numerical issues might happen when we are dealing with too small or too big numbers since we need to represent infinitely many real numbers with a finite number of bit patterns.\n",
    "One issue is underflow; it occurs when numbers near zero are rounded to zero.\n",
    "The other one is overflow; it occurs when numbers with large magnitude are approximated as $\\infty$ or $-\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. Suggest a remedy (with explanation on why it works) to overcome these numerical issues occuring with Softmax computation. Prove that this remedy actually does not change the softmax criteria. Describe a situation where the proposed remedy still fails to remove instability. ($1$ point)\n",
    "\n",
    "\n",
    "> 1/1. Exactly!\n",
    "\n",
    "These difficulties can be resolved by instead evaluating $softmax(z)$ where $ z = x - max_ix_i$. Since we only add or subtract a scalar from the input vector, the result is not effected.\n",
    "\n",
    "Shortly we will represent the maximum element of vector $x$ with $max$ then; \n",
    "$$ \\frac{exp(x_i - max)}{\\sum_{j=1}^n exp(x_j - max)}$$    \n",
    "\n",
    "$$ \\frac{exp(x_i)exp(-max)}{\\sum_{j=1}^n [exp(x_j) exp(-max)]}$$\n",
    "\n",
    "$$ \\frac{exp(x_i)exp(-max)}{(\\sum_{j=1}^n exp(x_j)) exp(-max)} = \\frac{exp(x_i)}{\\sum_{j=1}^n exp(x_j)}$$\n",
    "\n",
    "However the error still can occur if we implement log softmax(x) by first running the softmax subroutine then passing the result to the log function, we could erroneously obtain $-\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. First write a naive Softmax implementation, in numpy, that can produce numerical instability. Then write a modified Softmax implementation which is numerically stable.  ($0.5 + 0.5 = 1$ points)\n",
    "> 1/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5 10 15 20 25 30 35 40 45 50 55]\n",
      "[  1.29082491e-24   1.91575403e-22   2.84323108e-20   4.21972907e-18\n",
      "   6.26263322e-16   9.29457180e-14   1.37943676e-11   2.04726568e-09\n",
      "   3.03841167e-07   4.50940274e-05   6.69254707e-03   9.93262053e-01]\n",
      "[  1.29082491e-24   1.91575403e-22   2.84323108e-20   4.21972907e-18\n",
      "   6.26263322e-16   9.29457180e-14   1.37943676e-11   2.04726568e-09\n",
      "   3.03841167e-07   4.50940274e-05   6.69254707e-03   9.93262053e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO : Define inputs\n",
    "inputs = np.arange(0,60,5)\n",
    "print (inputs)\n",
    "\n",
    "def softmax_naive(inputs):\n",
    "    exp_array = np.exp(inputs)\n",
    "    return (exp_array/(np.sum(exp_array)))\n",
    "\n",
    "def softmax_modified(inputs):\n",
    "    z = inputs - np.amax(inputs) \n",
    "    exp_array = np.exp(z)\n",
    "    return (exp_array/(np.sum(exp_array)))\n",
    "\n",
    "print (softmax_naive(inputs))\n",
    "print (softmax_modified(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis $~$ (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4$. Is PCA supervised or unsupervised, logically explain your answer. Which is the tunable parameter in PCA?\n",
    "Briefly explain the role of this parameter in PCA.  ($1+0.5+0.5 = 2$ points)\n",
    "> 2/2\n",
    "\n",
    " 1) Unsupervised,PCA helps in producing low dimensional representation of the dataset by identifying a set of linear combination of features which have maximum variance and are mutually un-correlated. This linear dimensionality technique could be helpful in understanding latent interaction between the variable in an unsupervised setting. In a supervised setting such as Classification or Regression, one observes both a set of input variables(X1, .. Xn ) and response or output variables (Y). However, in un-supervised setting the goal is to identify “meaningful” informative patterns in the given data. There is no corresponding output Y of each input X here in PCA. \n",
    "\n",
    " 2) Tunable parameter is what we want to reduce the dimension to,here in this Task 4, we reduce dimensions from 2 to 1. \n",
    "\n",
    " 3) The encoding formula,  $f(x)=D^Tx$, D contains the eigenvectors corresponding to the larger eigenvalues of $X^TX$, so the column of D represents the degree of matrix after reducing dimensions.In PCA, the eigendecomposition is to tune this parameter, we want to use lower dimensions of data to represents the oringinal one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5$. Consider the following data:\n",
    "\n",
    "> 5/5\n",
    "\n",
    "setA: ${\\bf x}^{(1)}$=$(2, 4)^T$, ${\\bf x}^{(2)}$=$(2, 2)^T$, ${\\bf x}^{(3)}$=$(3, 1)^T$, ${\\bf x}^{(4)}$=$(5, 1)^T$ \n",
    "\n",
    "setB: ${\\bf x}^{(1)}$=$(-1, 1)^T$, ${\\bf x}^{(2)}$=$(-2, 2)^T$, ${\\bf x}^{(3)}$=$(-1, 3)^T$, ${\\bf x}^{(4)}$=$(-1, 4)^T$\n",
    "\n",
    "$(a)$ Compress the above sets of vectors into a one-dimensional set using PCA, i.e., derive the encoder function $f(x)=D^{T}x$ as defined in the lecture. Then apply f to the datasets inorder to compress them. ($1.5 + 1.5$ points)\n",
    "\n",
    "$\\mathbf{SetA}=\\left[\\begin{array}{cccc}\n",
    "   2 & 4\\\\\n",
    "   2 & 2\\\\\n",
    "   3 & 1\\\\\n",
    "   5 & 1\\\\\n",
    "  \\end{array}\\right]$   ,    Mean of vectors in Set A: $\\mathbf{MeanA}=\\left[\\begin{array}{cccc}\n",
    "   3 & 2\\\\ \n",
    "  \\end{array}\\right]$\n",
    "  Remove mean, $\\mathbf{X}=\\left[\\begin{array}{cccc}\n",
    "   -1 & 2\\\\\n",
    "   -1 & 0\\\\\n",
    "   0 & -1\\\\\n",
    "   2 & 1\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "  $\\mathbf{x=X^T}=\\left[\\begin{array}{cccc}\n",
    "   -1 & -1 & 0 & 2\\\\\n",
    "   2 & 0 & -1 & -1\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "  \n",
    "  $$\\mathbf{X^TX}=\\left[\\begin{array}{cccc}\n",
    "   6 & -4\\\\\n",
    "  -4 &  6\\\\\n",
    "  \\end{array}\\right] $$Make Eigendecomposition of $X^TX$,\n",
    " let $|X^TX-\\lambda I|=0$\n",
    " The larger eigenvalue is:$\\lambda_1=10$\n",
    " \n",
    " From $|X^TX-10I|=0$, we have D containing the eigenvectors corresponding to the largest eigenvalues of $X^TX$,\n",
    "  $\\mathbf{D_1}=\\left[\\begin{array}{cccc}\n",
    "   \\frac{\\sqrt{2}}{2}\\\\\n",
    "  \\frac{\\sqrt{2}}{-2}\n",
    "  \\end{array}\\right]$ \n",
    "\n",
    "Now we encode the data,$\\mathbf{D_1^Tx}=\\left[\\begin{array}{cccc}\n",
    "   \\frac{-3\\sqrt{2}}{2} &\n",
    "   \\frac{\\sqrt{2}}{-2}  &\n",
    "   \\frac{\\sqrt{2}}{2}   &\n",
    "   \\frac{3\\sqrt{2}}{2}\\\\\n",
    "  \\end{array}\\right]$ \n",
    "\n",
    "As to $\\mathbf{SetB}=\\left[\\begin{array}{cccc}\n",
    "   -1 & 1\\\\\n",
    "   -2 & 2\\\\\n",
    "   -1 & 3\\\\\n",
    "   -1 & 4\\\\\n",
    "  \\end{array}\\right]$,\n",
    "following the same steps, we have $\\mathbf{Y}=\\left[\\begin{array}{cccc}\n",
    "   0.25 & -1.5\\\\\n",
    "   -0.75 & 0.5\\\\\n",
    "   0.25 & 0.5\\\\\n",
    "   0.25 & 1.5\\\\\n",
    "  \\end{array}\\right]$ , as to Y,\n",
    "the larger eigenvalue is $\\lambda_2=5.058$,\n",
    "  $\\mathbf{D_2}=\\left[\\begin{array}{cccc}\n",
    "   0.1153\\\\\n",
    "   0.9933\\\\\n",
    "  \\end{array}\\right]$ \n",
    "  Now we encode the data,$\\mathbf{D_2^Ty}=\\left[\\begin{array}{cccc}\n",
    "   -1.4611 &-0.5831 & 0.5255 & 1.5188\n",
    "   \\\\\n",
    "  \\end{array}\\right]$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$. For both the above sets sketch the corresponding datasets in a separate figure. \n",
    "Also include the reconstructed vectors into the corresponding figures. ($2$ points)\n",
    "\n",
    "$ reconstructed vector_1=D_1D_1^Tx=\\left[\\begin{array}{cccc}\n",
    "   -1.5 & -.5 & 0.5 & 1.5\\\\\n",
    "   1.5 & 0.5 &-.5 & -1.5\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "$ reconstructed vector_2=D_2D_2^Ty=\\left[\\begin{array}{cccc}\n",
    "   -0.1685 & -0.0672 & 0.0606 & 0.1751\\\\\n",
    "   -1.4513 & -0.5792 & 0.5220 & 1.5083\\\\\n",
    "  \\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEREAkoBICISUAoAEZGA+v+O5esrBNJETwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ff08755c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wNps9RYigERhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ff0796128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1=np.array([-1,-1,0,2])\n",
    "y1=np.array([2,0,-1,-1])\n",
    "\n",
    "x1_rec=np.array([-1.5,-0.5,0.5,1.5])\n",
    "y1_rec=np.array([1.5,0.5,-0.5,-1.5])\n",
    "\n",
    "\n",
    "plt.scatter(x1, y1)\n",
    "plt.scatter(x1_rec, y1_rec)\n",
    "\n",
    "plt.legend(['original of set A', 'reconstructed of set A'], loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "x2=np.array([0.25,-0.75,0.25,0.25])\n",
    "y2=np.array([-1.5,-0.5,0.5,1.5])\n",
    "\n",
    "x2_rec=np.array([-0.1685,-0.0672,0.0606,0.1751])\n",
    "y2_rec=np.array([-1.4513,-0.5792,0.5220,1.5086])\n",
    "\n",
    "\n",
    "plt.scatter(x2, y2)\n",
    "plt.scatter(x2_rec, y2_rec)\n",
    "\n",
    "plt.legend(['original of set B', 'reconstructed of set B'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent and Newton's method $~$ (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose $f(x) = 2x^3 - 5x + 6$ **\n",
    "\n",
    "$6$. Write down the mathematical expressions for minimizing f(x) using Gradient descent(GD) and then using Newton's Method(NM). ($1$ points)\n",
    "\n",
    "> 1/1\n",
    "\n",
    "- Gradient descent : $x' = x - \\epsilon \\nabla_x f(x)$ where $x'$ is the updated point, $\\nabla_x f(x)$ is the gradient of $f$ and $\\epsilon$ is the learning rate, a positive scalar determining the size of the step.\n",
    "    For the above function $\\nabla_x f(x) = 6x^2 - 5$ therefore $x' = x - \\epsilon (6x^2 - 5)$.\n",
    "- Newton's Method : $x' = x - H(f)(x)^{-1} \\nabla_x f(x)$ where $ H(f)(x) $ Hessian matrix of $f$. \n",
    "    Since we have only one variable in the function the Hessian is $ H(f)(x) = f''(x) $ therefore $x' = x - (12x)^{-1} (6x^2 -5)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$7$. Report the updated values of x, both for GD and NM, at $x = 0$. what do you observe? ($1$ points)\n",
    "\n",
    "> 0.5/1. Actually, we have division by zero in NM!\n",
    "\n",
    "- GD: $\\nabla_x f(x) = 6x^2 - 5$ at $x = 0$;  $\\nabla_x f(0) = - 5$ \n",
    "\n",
    "    $x' = 0 - \\epsilon \\nabla_x f(0)$ therefore the updated value $x' = 5\\epsilon $\n",
    "    assuming $\\epsilon = 0.01 $ then we have $x' = 0.05$\n",
    "    \n",
    "- NM: $ H(f)(x)_{i,j} = \\frac{\\partial^2} {\\partial x_i \\partial x_j} \\rightarrow  H(f)(x) = [12x] $ \n",
    "     \n",
    "    $x' = x - (12x)^{-1} (6x^2 -5)$ for $x = 0$ we have $x' = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$8$. Perform GD and NM for the above function using Tensorflow. ($1.5 + 1.5$ points)\n",
    "\n",
    "> 3/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "fx = 2*x**3 - 5*x + 6\n",
    "dfx = tf.gradients(fx, x)[0]\n",
    "eps = 0.01\n",
    "x_upd = x - eps*dfx\n",
    "x_upd_out = sess.run(x_upd, feed_dict = {x: 0.0})\n",
    "\n",
    "print (x_upd_out)\n",
    "# TODO : Implement Gradient Descent with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "fx = 2*x**3 - 5*x + 6\n",
    "dfx = tf.gradients(fx, x)[0]\n",
    "ddfx = tf.gradients(dfx, x)[0]\n",
    "x_upd = x - dfx*(ddfx)**(-1)\n",
    "x_upd_out = sess.run(x_upd, feed_dict = {x: 0.0})\n",
    "\n",
    "print (x_upd_out)\n",
    "# TODO : Implement Newton's Method with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent computation and visualisation $~$ (3 + 2 points)\n",
    "\n",
    "> 0/5. No solution :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now visualize the Gradient Descent algorithm to fit a straight line to data generated using  $y = \\theta_{true}x$ $~$, i.e., use this expression to first produce the data (see code below the lines starting with m=20 and following) and then try to fit a straight line to this data. Fitting a straight line means that you have to approximate this $\\theta_{true}$ parameter using the hypothesis or predictive model by minimizing the cost function defined below.\n",
    "\n",
    "**For this task you should minimize a cost function of the form:**\n",
    "$$\\frac{1}{2m}\\sum_{i=1}^m [h_{\\theta}(x^i)-y^i]^2$$\n",
    "where\n",
    "- $x^i$ is the $i^{th}$ input \n",
    "\n",
    "- $y^i$ is the true $i^{th}$ response or output\n",
    "\n",
    "- $h_{\\theta}(x)$ is the hypothesis or predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assume $~$ $h_{\\theta}(x) = \\theta x$ $~$ to be the hypothesis or predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114a29278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the true data which is to be fitted\n",
    "m = 20                      # number of data points for x\n",
    "theta_true = 0.5            # corresponds to the true slope\n",
    "x = np.linspace(-1,1,m)     # x values or inputsm\n",
    "y = theta_true * x          # True response\n",
    "\n",
    "# Create a subplot window\n",
    "# On the left window plot the true data and the approximation that you obtain with different estimates of the slope theta_true\n",
    "# on the right window plot the cost function \n",
    "# TODO : Create the subplot window\n",
    "\n",
    "def hypothesis(x, theta):\n",
    "    \"\"\"Our \"hypothesis or predictive model\", a straight line through the origin.\"\"\"\n",
    "    return x*theta\n",
    "\n",
    "def cost_func(theta):\n",
    "    \"\"\"The cost function describing the goodness of fit.\"\"\"  \n",
    "    y_hypo = hypothesis(x, theta)\n",
    "    return (1/2*m)* np.sum((y_hypo-y)**2)\n",
    "\n",
    "\n",
    "# First construct a grid of theta parameter and their corresponding\n",
    "# cost function values.\n",
    "theta_grid = np.linspace(-0.2,1,50)\n",
    "\n",
    "cost_values = [cost_func(i) for i in theta_grid]\n",
    "J_grid = np.matrix([theta_grid, cost_values])\n",
    "\n",
    "# Find the cost function values to be stored in J_grid\n",
    "# TODO : Create J_grid\n",
    "\n",
    "\n",
    "# Plot the cost function as a function of theta.\n",
    "# TODO : Do the plot\n",
    "theta1=0.7\n",
    "y_theta1=theta1 * x \n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,y_theta1)\n",
    "plt.subplot(122)\n",
    "plt.plot(theta_grid, cost_values)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Take N steps with learning rate alpha down the steepest gradient,\n",
    "# starting at theta = 0.\n",
    "N = 10\n",
    "alpha = 1 \n",
    "\n",
    "#try also 0.02 to see what happens\n",
    "\n",
    "# this is just a starting value of alpha, \n",
    "# you must consider different values of alpha (try using large values)\n",
    "# and redo the steps below to generate different plots\n",
    "theta = [0]\n",
    "\n",
    "\n",
    "\n",
    "# TODO :Compute the N steps down the steepest gradient\n",
    "\n",
    "# TODO : Annotate the cost function plot with coloured points indicating the\n",
    "# parameters chosen and red arrows indicating the steps down the gradient.\n",
    "# Also plot the fit function on the left window of the subplot in a matching colour.\n",
    "\n",
    "# TODO : Put the labels, titles and a legend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now assume that the data is generated using  $y = \\theta_1x + \\theta_0$\n",
    "** Following the same logic you applied for the above task define a predictive model \n",
    "and perform 5 steps of gradient descent with learning rate alpha = 0.7 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the true data which is to be fitted\n",
    "m = 20\n",
    "theta0_true = 2\n",
    "theta1_true = 0.5\n",
    "x = np.linspace(-1,1,m)\n",
    "y = theta0_true + theta1_true * x\n",
    "\n",
    "# Create the sub-plot: left window is the data, right window will be the cost function.\n",
    "# TODO\n",
    "\n",
    "\n",
    "def hypothesis(x, theta0, theta1):\n",
    "    \"\"\"Our \"hypothesis function\", a straight line.\"\"\"\n",
    "    \n",
    "    # TODO : Implement\n",
    "    pass\n",
    "\n",
    "def cost_func(theta0, theta1):\n",
    "    \"\"\"The cost function, J(theta0, theta1) describing the goodness of fit.\"\"\"\n",
    "    \n",
    "    # TODO : Implement\n",
    "    pass\n",
    "\n",
    "\n",
    "# First construct a grid of (theta0, theta1) parameter pairs and their\n",
    "# corresponding cost function values.\n",
    "theta0_grid = np.linspace(-1,4,101)\n",
    "theta1_grid = np.linspace(-5,5,101)\n",
    "\n",
    "# TODO : Compute the cost function values\n",
    "\n",
    "\n",
    "# TODO : Do a labeled contour plot for the cost function on right window of the above subplot\n",
    "\n",
    "\n",
    "# TODO : Take 5 steps with learning rate alpha = 0.7 down the steepest gradient,\n",
    "# starting at (theta0, theta1) = (0, 0).\n",
    "\n",
    "\n",
    "# TODO : Annotate the cost function plot with coloured points indicating the\n",
    "# parameters chosen and red arrows indicating the steps down the gradient.\n",
    "# Also plot the fit function on the left window in a matching colour.\n",
    "\n",
    "\n",
    "# TODO : Add the labels, titles and a legend to the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra Bonus\n",
    "- [Additional material - Linear Algebra Basics](http://www.cs.ubc.ca/~schmidtm/Documents/2009_Notes_LinearAlgebra.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace of a Matrix $~$ (3 points)\n",
    "- [Reading material on Trace](https://en.wikipedia.org/wiki/Trace_(linear_algebra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prove that the trace of a ***symmetric positive definite*** matrix is the sum of its eigenvalues.    ($0.5$ points)\n",
    "\n",
    "> 0.5 / 3\n",
    "\n",
    "- The trace operator gives the sum of all of the diagonal entries of a matrix: \n",
    "$$Tr(A)=\\sum_i{A_{i,j}}$$\n",
    "if we choose any orthonormal basis $v_1,…,v_n$ for $\\mathbb{R_n}$ (with respect to the standard inner product $\\langle\\cdot,\\cdot\\rangle$) then\n",
    "$$Tr(A)=\\sum_i{\\langle Av_i,v_i\\rangle}$$\n",
    "\n",
    "If A is symmetric, then by choosing $v_1,…,v_n$ to be an orthonormal basis of eigenvectors of $A$ (with $Avi=\\lambda_iv_i$), we immediately get\n",
    "\n",
    "$$Tr(A)=\\sum_i{\\langle Av_i,v_i\\rangle} = \\sum_i{\\langle \\lambda_iv_i,v_i\\rangle} = \\sum_i{\\lambda_i} $$\n",
    "\n",
    "Suppose $\\mathbf{Y}$ is a $m \\times n$ matrix with $m \\leq n$ and has ***full rank***, then:\n",
    "\n",
    "\n",
    "\n",
    "$(a)$.   Give the rank of $\\mathbf{Y}$.                                                                 ($0.5$ points)\n",
    "\n",
    "rank($\\mathbf{Y}$) = m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$.  Show that trace of $\\mathbf{Y}^{T}(\\mathbf{Y}^T\\mathbf{Y})^{-1}\\mathbf{Y}$ = rank($\\mathbf{Y}$)                                     ($1$ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(c)$. Prove that $\\mathbf{Y}^{T}(\\mathbf{Y}^T\\mathbf{Y})^{-1}\\mathbf{Y}$ is the projection matrix w.r.t space defined by $\\mathbf{Y}$.     ($1$ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacobian $~$ (3 points)\n",
    "\n",
    "> 3/3\n",
    "\n",
    "***[Reading material on Jacobian](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the Jacobian determinant of $\\frac{\\partial(fg, h)}{\\partial(u, v)}$ is equal to $\\frac{\\partial(f, h)}{\\partial(u, v)}g + f\\frac{\\partial(g, h)}{\\partial(u, v)}$,\n",
    "\n",
    "where $f$,$g$, and $h$ are functions of $u$ and $v$ (i.e., $f(u,v)$, $g(u,v)$, and $h(u,v)$)   ($3$ points)\n",
    "\n",
    "Hint: Use the property $\\frac{\\partial(y, x)}{\\partial(u, v)} = \\frac{\\partial(y)}{\\partial(u)}\\frac{\\partial(x)}{\\partial(v)}-\\frac{\\partial(y)}{\\partial(v)}\\frac{\\partial(x)}{\\partial(u)}$\n",
    "\n",
    "\n",
    "Direct calculation leads to:\n",
    " $\\frac{\\partial(fg, h)}{\\partial(u, v)}$=$\\frac{\\partial(fg)}{\\partial(u)}$$\\frac{\\partial(h)}{\\partial(v)}$-$\\frac{\\partial(fg)}{\\partial(v)}$ $\\frac{\\partial(h)}{\\partial(u)}$=($\\frac{\\partial(f)}{\\partial(u)}g$+$\\frac{\\partial(g)}{\\partial(u)}f)$$\\frac{\\partial(h)}{\\partial(v)}$-($\\frac{\\partial(f)}{\\partial(v)}g$+$\\frac{\\partial(g)}{\\partial(v)}f)$$\\frac{\\partial(h)}{\\partial(u)}$=($\\frac{\\partial(f)}{\\partial(u)}$$\\frac{\\partial(h)}{\\partial(v)}$-$\\frac{\\partial(f)}{\\partial(v)}$$\\frac{\\partial(h)}{\\partial(u)}$)g+($\\frac{\\partial(g)}{\\partial(u)}$$\\frac{\\partial(h)}{\\partial(v)}$-$\\frac{\\partial(g)}{\\partial(v)}$$\\frac{\\partial(h)}{\\partial(u)}$)f=$\\frac{\\partial(f, h)}{\\partial(u, v)}g + f\\frac{\\partial(g, h)}{\\partial(u, v)}$\n",
    " \n",
    " \n",
    " Proved\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hessian $~$ (2 points)\n",
    "> 2/2\n",
    "***[Reading material on Hessian](https://en.wikipedia.org/wiki/Hessian_matrix)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{M}=\\left[\\begin{array}{cccc}\n",
    "   5 & 1 & 0 & 1\\\\\n",
    "   1 & 4 & 1 & 0\\\\\n",
    "   0 & 1 & 3 & 1\\\\\n",
    "   1 & 0 & 1 & 2\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "denote the Hessian matrix at particular point for a particular function.\n",
    "\n",
    "$(a)$. What properties of the functional can you infer from the above information.(give mathematical reasons) ($1$ point)\n",
    "\n",
    "Set $|M-\\lambda I|=0$\n",
    "The eingenvalues are $1, 3, 4 ,6 $ which are pisitive values, so M is positive defined. It means at this particular point, it is a local minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$. Provide a generic mathematical representation (e.g. the generic representation of a straight line is $ax+by+c=0$) for the above function. ($1$ point)\n",
    "$ \\frac{5}{2}x_1^2+x_1x_2+x_1x_4+2x_2^2+x_2x_3+x_3x_4+x_4^2+\\frac{3x_3^2 }{2}+c=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 20/20 due to bonus points. Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
