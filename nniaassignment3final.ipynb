{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment sheet 3: Numerical Computation and Prinicipal Component Analysis (Deadline: Nov 24, 23:59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set notebook to full width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Issues with Softmax $~$ (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture you were introduced to the softmax function which is used to generate probabilities corresponding to the output labels. Typically, the input to the softmax function is a vector of numerical values over the labels and the output is a vector(of same dimension as the input vector) of corresponding probabilities.\n",
    "**Softmax function is given by,** $~$\n",
    "$$Softmax(x)_i = \\frac{exp(x_i)}{\\sum_{j=1}^n exp(x_j)}$$\n",
    "\n",
    "**Numerical issues might occur when computing softmax functions on a computer which can perform computations\n",
    "only upto a certain precision.** [Suggested reading $-$ [chapter 4.1 of DeepLearningBook](http://www.deeplearningbook.org/contents/numerical.html)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$. Name these numerical issues and explain them. ($1$ points)\n",
    "\n",
    "Numerical issues might happen when we are dealing with too small or too big numbers since we need to represent infinitely many real numbers with a finite number of bit patterns.\n",
    "One issue is underflow; it occurs when numbers near zero are rounded to zero.\n",
    "The other one is overflow; it occurs when numbers with large magnitude are approximated as $\\infty$ or $-\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. Suggest a remedy (with explanation on why it works) to overcome these numerical issues occuring with Softmax computation. Prove that this remedy actually does not change the softmax criteria. Describe a situation where the proposed remedy still fails to remove instability. ($1$ point)\n",
    "\n",
    "These difficulties can be resolved by instead evaluating $softmax(z)$ where $ z = x - max_ix_i$. Since we only add or subtract a scalar from the input vector, the result is not effected.\n",
    "\n",
    "Shortly we will represent the maximum element of $x_i$ with $max$ then; \n",
    "$$ \\frac{exp(x_i - max)}{\\sum_{j=1}^n exp(x_j - max)}$$    \n",
    "\n",
    "$$ \\frac{exp(x_i)exp(-max)}{\\sum_{j=1}^n [exp(x_j) exp(-max)]}$$\n",
    "\n",
    "$$ \\frac{exp(x_i)exp(-max)}{(\\sum_{j=1}^n exp(x_j)) exp(-max)} = \\frac{exp(x_i)}{\\sum_{j=1}^n exp(x_j)}$$\n",
    "\n",
    "However the error still can occur if we implement log softmax(x) by first running the softmax subroutine then passing the result to the log function, we could erroneously obtain $-\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. First write a naive Softmax implementation, in numpy, that can produce numerical instability. Then write a modified Softmax implementation which is numerically stable.  ($0.5 + 0.5 = 1$ points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5 10 15 20 25 30 35 40 45 50 55]\n",
      "[  1.29082491e-24   1.91575403e-22   2.84323108e-20   4.21972907e-18\n",
      "   6.26263322e-16   9.29457180e-14   1.37943676e-11   2.04726568e-09\n",
      "   3.03841167e-07   4.50940274e-05   6.69254707e-03   9.93262053e-01]\n",
      "[  1.29082491e-24   1.91575403e-22   2.84323108e-20   4.21972907e-18\n",
      "   6.26263322e-16   9.29457180e-14   1.37943676e-11   2.04726568e-09\n",
      "   3.03841167e-07   4.50940274e-05   6.69254707e-03   9.93262053e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO : Define inputs\n",
    "inputs = np.arange(0,60,5)\n",
    "print (inputs)\n",
    "\n",
    "def softmax_naive(inputs):\n",
    "    exp_array = np.exp(inputs)\n",
    "    return (exp_array/(np.sum(exp_array)))\n",
    "\n",
    "def softmax_modified(inputs):\n",
    "    z = inputs - np.amax(inputs) \n",
    "    exp_array = np.exp(z)\n",
    "    return (exp_array/(np.sum(exp_array)))\n",
    "\n",
    "print (softmax_naive(inputs))\n",
    "print (softmax_modified(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis $~$ (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4$. Is PCA supervised or unsupervised, logically explain your answer. Which is the tunable parameter in PCA?\n",
    "Briefly explain the role of this parameter in PCA.  ($1+0.5+0.5 = 2$ points)\n",
    "\n",
    " 1) Unsupervised,PCA helps in producing low dimensional representation of the dataset by identifying a set of linear combination of features which have maximum variance and are mutually un-correlated. This linear dimensionality technique could be helpful in understanding latent interaction between the variable in an unsupervised setting. In a supervised setting such as Classification or Regression, one observes both a set of input variables(X1, .. Xn ) and response or output variables (Y). However, in un-supervised setting the goal is to identify “meaningful” informative patterns in the given data. There is no corresponding output Y of each input X here in PCA. \n",
    "\n",
    " 2) Tunable parameter is what we want to reduce the dimension to,here in this Task 4, we reduce dimensions from 2 to 1. \n",
    "\n",
    " 3) The encoding formula,  $f(x)=D^Tx$, D contains the eigenvectors corresponding to the larger eigenvalues of $X^TX$, so the column of D represents the degree of matrix after reducing dimensions.In PCA, the eigendecomposition is to tune this parameter, we want to use lower dimensions of data to represents the oringinal one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5$. Consider the following data:\n",
    "\n",
    "setA: ${\\bf x}^{(1)}$=$(2, 4)^T$, ${\\bf x}^{(2)}$=$(2, 2)^T$, ${\\bf x}^{(3)}$=$(3, 1)^T$, ${\\bf x}^{(4)}$=$(5, 1)^T$ \n",
    "\n",
    "setB: ${\\bf x}^{(1)}$=$(-1, 1)^T$, ${\\bf x}^{(2)}$=$(-2, 2)^T$, ${\\bf x}^{(3)}$=$(-1, 3)^T$, ${\\bf x}^{(4)}$=$(-1, 4)^T$\n",
    "\n",
    "$(a)$ Compress the above sets of vectors into a one-dimensional set using PCA, i.e., derive the encoder function $f(x)=D^{T}x$ as defined in the lecture. Then apply f to the datasets inorder to compress them. ($1.5 + 1.5$ points)\n",
    "\n",
    "$\\mathbf{SetA}=\\left[\\begin{array}{cccc}\n",
    "   2 & 4\\\\\n",
    "   2 & 2\\\\\n",
    "   3 & 1\\\\\n",
    "   5 & 1\\\\\n",
    "  \\end{array}\\right]$   ,    Mean of vectors in Set A: $\\mathbf{MeanA}=\\left[\\begin{array}{cccc}\n",
    "   3 & 2\\\\ \n",
    "  \\end{array}\\right]$\n",
    "  Remove mean, $\\mathbf{X}=\\left[\\begin{array}{cccc}\n",
    "   -1 & 2\\\\\n",
    "   -1 & 0\\\\\n",
    "   0 & -1\\\\\n",
    "   2 & 1\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "  $\\mathbf{x=X^T}=\\left[\\begin{array}{cccc}\n",
    "   -1 & -1 & 0 & 2\\\\\n",
    "   2 & 0 & -1 & -1\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "  \n",
    "  $$\\mathbf{X^TX}=\\left[\\begin{array}{cccc}\n",
    "   6 & -4\\\\\n",
    "  -4 &  6\\\\\n",
    "  \\end{array}\\right] $$Make Eigendecomposition of $X^TX$,\n",
    " let $|X^TX-\\lambda I|=0$\n",
    " The larger eigenvalue is:$\\lambda_1=10$\n",
    " \n",
    " From $|X^TX-10I|=0$, we have D containing the eigenvectors corresponding to the largest eigenvalues of $X^TX$,\n",
    "  $\\mathbf{D_1}=\\left[\\begin{array}{cccc}\n",
    "   \\frac{\\sqrt{2}}{2}\\\\\n",
    "  \\frac{\\sqrt{2}}{-2}\n",
    "  \\end{array}\\right]$ \n",
    "\n",
    "Now we encode the data,$\\mathbf{D_1^Tx}=\\left[\\begin{array}{cccc}\n",
    "   \\frac{-3\\sqrt{2}}{2} &\n",
    "   \\frac{\\sqrt{2}}{-2}  &\n",
    "   \\frac{\\sqrt{2}}{2}   &\n",
    "   \\frac{3\\sqrt{2}}{2}\\\\\n",
    "  \\end{array}\\right]$ \n",
    "\n",
    "As to $\\mathbf{SetB}=\\left[\\begin{array}{cccc}\n",
    "   -1 & 1\\\\\n",
    "   -2 & 2\\\\\n",
    "   -1 & 3\\\\\n",
    "   -1 & 4\\\\\n",
    "  \\end{array}\\right]$,\n",
    "following the same steps, we have $\\mathbf{Y}=\\left[\\begin{array}{cccc}\n",
    "   0.25 & -1.5\\\\\n",
    "   -0.75 & 0.5\\\\\n",
    "   0.25 & 0.5\\\\\n",
    "   0.25 & 1.5\\\\\n",
    "  \\end{array}\\right]$ , as to Y,\n",
    "the larger eigenvalue is $\\lambda_2=5.058$,\n",
    "  $\\mathbf{D_2}=\\left[\\begin{array}{cccc}\n",
    "   0.1153\\\\\n",
    "   0.9933\\\\\n",
    "  \\end{array}\\right]$ \n",
    "  Now we encode the data,$\\mathbf{D_2^Ty}=\\left[\\begin{array}{cccc}\n",
    "   -1.4611 &-0.5831 & 0.5255 & 1.5188\n",
    "   \\\\\n",
    "  \\end{array}\\right]$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$. For both the above sets sketch the corresponding datasets in a separate figure. \n",
    "Also include the reconstructed vectors into the corresponding figures. ($2$ points)\n",
    "\n",
    "$ reconstructed vector_1=D_1D_1^Tx=\\left[\\begin{array}{cccc}\n",
    "   -1.5 & -.5 & 0.5 & 1.5\\\\\n",
    "   1.5 & 0.5 &-.5 & -1.5\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "$ reconstructed vector_2=D_2D_2^Ty=\\left[\\begin{array}{cccc}\n",
    "   -0.1685 & -0.0672 & 0.0606 & 0.1751\\\\\n",
    "   -1.4513 & -0.5792 & 0.5220 & 1.5083\\\\\n",
    "  \\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9KoTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106b85eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na/uBEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108431908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1=np.array([-1,-1,0,2])\n",
    "y1=np.array([2,0,-1,-1])\n",
    "\n",
    "x1_rec=np.array([-1.5,-0.5,0.5,1.5])\n",
    "y1_rec=np.array([1.5,0.5,-0.5,-1.5])\n",
    "\n",
    "\n",
    "plt.scatter(x1, y1)\n",
    "plt.scatter(x1_rec, y1_rec)\n",
    "\n",
    "plt.legend(['original of set A', 'reconstructed of set A'], loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "x2=np.array([0.25,-0.75,0.25,0.25])\n",
    "y2=np.array([-1.5,-0.5,0.5,-1.5])\n",
    "\n",
    "x2_rec=np.array([-0.1685,-0.0672,0.0606,0.1751])\n",
    "y2_rec=np.array([-1.4513,-0.5792,0.5220,1.5086])\n",
    "\n",
    "\n",
    "plt.scatter(x2, y2)\n",
    "plt.scatter(x2_rec, y2_rec)\n",
    "\n",
    "plt.legend(['original of set B', 'reconstructed of set B'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent and Newton's method $~$ (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose $f(x) = 2x^3 - 5x + 6$ **\n",
    "\n",
    "$6$. Write down the mathematical expressions for minimizing f(x) using Gradient descent(GD) and then using Newton's Method(NM). ($1$ points)\n",
    "\n",
    "- Gradient descent : $x' = x - \\epsilon \\nabla_x f(x)$ where $x'$ is the updated point, $\\nabla_x f(x)$ is the gradient of $f$ and $\\epsilon$ is the learning rate, a positive scalar determining the size of the step.\n",
    "    For the above function $\\nabla_x f(x) = 6x^2 - 5$ therefore $x' = x - \\epsilon (6x^2 - 5)$.\n",
    "- Newton's Method : $x' = x - H(f)(x)^{-1} \\nabla_x f(x)$ where $ H(f)(x) $ Hessian matrix of $f$. \n",
    "    Since we have only one variable in the function the Hessian is $ H(f)(x) = f''(x) $ therefore $x' = x - (12x)^{-1} (6x^2 -5)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$7$. Report the updated values of x, both for GD and NM, at $x = 0$. what do you observe? ($1$ points)\n",
    "\n",
    "- GD: $\\nabla_x f(x) = 6x^2 - 5$ at $x = 0$;  $\\nabla_x f(0) = - 5$ \n",
    "\n",
    "    $x' = 0 - \\epsilon \\nabla_x f(0)$ therefore the updated value $x' = 5\\epsilon $\n",
    "    assuming $\\epsilon = 0.01 $ then we have $x' = 0.05$\n",
    "    \n",
    "- NM: $ H(f)(x)_{i,j} = \\frac{\\partial^2} {\\partial x_i \\partial x_j} \\rightarrow  H(f)(x) = [12x] $ \n",
    "     \n",
    "    $x' = x - (12x)^{-1} (6x^2 -5)$ for $x = 0$ we have $x' = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$8$. Perform GD and NM for the above function using Tensorflow. ($1.5 + 1.5$ points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "fx = 2*x**3 - 5*x + 6\n",
    "dfx = tf.gradients(fx, x)[0]\n",
    "eps = 0.01\n",
    "x_upd = x - eps*dfx\n",
    "x_upd_out = sess.run(x_upd, feed_dict = {x: 0.0})\n",
    "\n",
    "print (x_upd_out)\n",
    "# TODO : Implement Gradient Descent with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "fx = 2*x**3 - 5*x + 6\n",
    "dfx = tf.gradients(fx, x)[0]\n",
    "ddfx = tf.gradients(dfx, x)[0]\n",
    "x_upd = x - dfx*(ddfx)**(-1)\n",
    "x_upd_out = sess.run(x_upd, feed_dict = {x: 0.0})\n",
    "\n",
    "print (x_upd_out)\n",
    "# TODO : Implement Newton's Method with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent computation and visualisation $~$ (3 + 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now visualize the Gradient Descent algorithm to fit a straight line to data generated using  $y = \\theta_{true}x$ $~$, i.e., use this expression to first produce the data (see code below the lines starting with m=20 and following) and then try to fit a straight line to this data. Fitting a straight line means that you have to approximate this $\\theta_{true}$ parameter using the hypothesis or predictive model by minimizing the cost function defined below.\n",
    "\n",
    "**For this task you should minimize a cost function of the form:**\n",
    "$$\\frac{1}{2m}\\sum_{i=1}^m [h_{\\theta}(x^i)-y^i]^2$$\n",
    "where\n",
    "- $x^i$ is the $i^{th}$ input \n",
    "\n",
    "- $y^i$ is the true $i^{th}$ response or output\n",
    "\n",
    "- $h_{\\theta}(x)$ is the hypothesis or predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assume $~$ $h_{\\theta}(x) = \\theta x$ $~$ to be the hypothesis or predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2 36.1052631579\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMqlTP+eIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114edd518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the true data which is to be fitted\n",
    "m = 20                      # number of data points for x\n",
    "theta_true = 0.5            # corresponds to the true slope\n",
    "x = np.linspace(-1,1,m)     # x values or inputsm\n",
    "y = theta_true * x          # True response\n",
    "\n",
    "# Create a subplot window\n",
    "# On the left window plot the true data and the approximation that you obtain with different estimates of the slope theta_true\n",
    "# on the right window plot the cost function \n",
    "# TODO : Create the subplot window\n",
    "\n",
    "def hypothesis(x, theta):\n",
    "    \"\"\"Our \"hypothesis or predictive model\", a straight line through the origin.\"\"\"\n",
    "    return x*theta\n",
    "\n",
    "def cost_func(theta):\n",
    "    \"\"\"The cost function describing the goodness of fit.\"\"\"  \n",
    "    y_hypo = hypothesis(x, theta)\n",
    "    return (1/2*m)* np.sum((y_hypo-y)**2)\n",
    "\n",
    "\n",
    "# First construct a grid of theta parameter and their corresponding\n",
    "# cost function values.\n",
    "theta_grid = np.linspace(-0.2,1,50)\n",
    "\n",
    "cost_values = [cost_func(i) for i in theta_grid]\n",
    "J_grid = np.matrix([theta_grid, cost_values])\n",
    "\n",
    "# Find the cost function values to be stored in J_grid\n",
    "# TODO : Create J_grid\n",
    "\n",
    "\n",
    "# Plot the cost function as a function of theta.\n",
    "# TODO : Do the plot\n",
    "theta1=0.7\n",
    "y_theta1=theta1 * x \n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,y_theta1)\n",
    "plt.subplot(122)\n",
    "plt.plot(theta_grid, cost_values)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Take N steps with learning rate alpha down the steepest gradient,\n",
    "# starting at theta = 0.\n",
    "N = 10\n",
    "alpha = 1 \n",
    "\n",
    "#try also 0.02 to see what happens\n",
    "\n",
    "# this is just a starting value of alpha, \n",
    "# you must consider different values of alpha (try using large values)\n",
    "# and redo the steps below to generate different plots\n",
    "theta = [0]\n",
    "\n",
    "\n",
    "# TODO :Compute the N steps down the steepest gradient\n",
    "\n",
    "# TODO : Annotate the cost function plot with coloured points indicating the\n",
    "# parameters chosen and red arrows indicating the steps down the gradient.\n",
    "# Also plot the fit function on the left window of the subplot in a matching colour.\n",
    "\n",
    "# TODO : Put the labels, titles and a legend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now assume that the data is generated using  $y = \\theta_1x + \\theta_0$\n",
    "** Following the same logic you applied for the above task define a predictive model \n",
    "and perform 5 steps of gradient descent with learning rate alpha = 0.7 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the true data which is to be fitted\n",
    "m = 20\n",
    "theta0_true = 2\n",
    "theta1_true = 0.5\n",
    "x = np.linspace(-1,1,m)\n",
    "y = theta0_true + theta1_true * x\n",
    "\n",
    "# Create the sub-plot: left window is the data, right window will be the cost function.\n",
    "# TODO\n",
    "\n",
    "\n",
    "def hypothesis(x, theta0, theta1):\n",
    "    \"\"\"Our \"hypothesis function\", a straight line.\"\"\"\n",
    "    \n",
    "    # TODO : Implement\n",
    "    pass\n",
    "\n",
    "def cost_func(theta0, theta1):\n",
    "    \"\"\"The cost function, J(theta0, theta1) describing the goodness of fit.\"\"\"\n",
    "    \n",
    "    # TODO : Implement\n",
    "    pass\n",
    "\n",
    "\n",
    "# First construct a grid of (theta0, theta1) parameter pairs and their\n",
    "# corresponding cost function values.\n",
    "theta0_grid = np.linspace(-1,4,101)\n",
    "theta1_grid = np.linspace(-5,5,101)\n",
    "\n",
    "# TODO : Compute the cost function values\n",
    "\n",
    "\n",
    "# TODO : Do a labeled contour plot for the cost function on right window of the above subplot\n",
    "\n",
    "\n",
    "# TODO : Take 5 steps with learning rate alpha = 0.7 down the steepest gradient,\n",
    "# starting at (theta0, theta1) = (0, 0).\n",
    "\n",
    "\n",
    "# TODO : Annotate the cost function plot with coloured points indicating the\n",
    "# parameters chosen and red arrows indicating the steps down the gradient.\n",
    "# Also plot the fit function on the left window in a matching colour.\n",
    "\n",
    "\n",
    "# TODO : Add the labels, titles and a legend to the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra Bonus\n",
    "- [Additional material - Linear Algebra Basics](http://www.cs.ubc.ca/~schmidtm/Documents/2009_Notes_LinearAlgebra.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace of a Matrix $~$ (3 points)\n",
    "- [Reading material on Trace](https://en.wikipedia.org/wiki/Trace_(linear_algebra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prove that the trace of a ***symmetric positive definite*** matrix is the sum of its eigenvalues.    ($0.5$ points)\n",
    "\n",
    "Suppose $\\mathbf{Y}$ is a $m \\times n$ matrix with $m \\leq n$ and has ***full rank***, then\n",
    "\n",
    "$(a)$.   Give the rank of $\\mathbf{Y}$.                                                                 ($0.5$ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$.  Show that trace of $\\mathbf{Y}^{T}(\\mathbf{Y}^T\\mathbf{Y})^{-1}\\mathbf{Y}$ = rank($\\mathbf{Y}$)                                     ($1$ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(c)$. Prove that $\\mathbf{Y}^{T}(\\mathbf{Y}^T\\mathbf{Y})^{-1}\\mathbf{Y}$ is the projection matrix w.r.t space defined by $\\mathbf{Y}$.     ($1$ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacobian $~$ (3 points)\n",
    "\n",
    "***[Reading material on Jacobian](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the Jacobian determinant of $\\frac{\\partial(fg, h)}{\\partial(u, v)}$ is equal to $\\frac{\\partial(f, h)}{\\partial(u, v)}g + f\\frac{\\partial(g, h)}{\\partial(u, v)}$,\n",
    "\n",
    "where $f$,$g$, and $h$ are functions of $u$ and $v$ (i.e., $f(u,v)$, $g(u,v)$, and $h(u,v)$)   ($3$ points)\n",
    "\n",
    "Hint: Use the property $\\frac{\\partial(y, x)}{\\partial(u, v)} = \\frac{\\partial(y)}{\\partial(u)}\\frac{\\partial(x)}{\\partial(v)}-\\frac{\\partial(y)}{\\partial(v)}\\frac{\\partial(x)}{\\partial(u)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hessian $~$ (2 points)\n",
    "***[Reading material on Hessian](https://en.wikipedia.org/wiki/Hessian_matrix)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{M}=\\left[\\begin{array}{cccc}\n",
    "   5 & 1 & 0 & 1\\\\\n",
    "   1 & 4 & 1 & 0\\\\\n",
    "   0 & 1 & 3 & 1\\\\\n",
    "   1 & 0 & 1 & 2\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "denote the Hessian matrix at particular point for a particular function.\n",
    "\n",
    "$(a)$. What properties of the functional can you infer from the above information.(give mathematical reasons) ($1$ point)\n",
    "\n",
    "Set $|M-\\lambda I|=0$\n",
    "The eingenvalues are $1, 3, 4 ,6 $ which are pisitive values, so M is positive defined. It means at this particular point, it is a local minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$. Provide a generic mathematical representation (e.g. the generic representation of a straight line is $ax+by+c=0$) for the above function. ($1$ point)\n",
    "$ \\frac{5}{2}x_1^2+x_1x_2+x_1x_4+2x_2^2+x_2x_3+x_3x_4+x_4^2+\\frac{3x_3^2 }{2}+c=0$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
