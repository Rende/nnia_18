{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Sheet 1:  Hands-on Linear Regression (deadline: 31 Oct, 14:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first exercise sheet is to make you familiar with **jupyter notebook** which we will use to run part of the exercises in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do so you have to implement a very naive algorithm to solve a **linear regression** problem: **Grid Search**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the simplest and also most widely used machine learning algorithms. It is used to model the relationship between a dependent variable $y$ and one or more independent (also called explanatory) variables $x$. Here, we will focus on the case where we just have a single indepenedent variable, so-called **simple linear regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given some inputs $x = \\{x_0, \\dots, x_n\\}$ and corresponding outputs $y = \\{y_0, \\dots, y_n\\}$. Linear regression assumes that there exists an (unknown!) linear relationship between the input and the output, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = f(x) = \\beta_0 + \\beta_1x + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\epsilon$ is an unobserved noise variable. This relationship is approximated as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = \\hat{f}(x; w_0, w_1) = w_0 + w_1x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the goal of linear regression is to estimate the unknown parameters $w_0$ and $w_1$ such that the error between the model prediction $\\hat{y}$ and the true output $y$ is minimized. Formaly, let the ith **residual** be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r_i = y_i - \\hat{f}(x_i; w_0, w_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. the difference between the ith output and the ith prediction and let"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S = \\sum\\limits_{i=1}^n r_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "be the sum of squared residuals. Then one tries to find the paramaters $w_0$ and $w_1$ that minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MSE = \\frac{1}{n}~S$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the so called **mean squared error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exercise: Fitting a Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will implement several functions which will help you to fit a simple linear regression model on training data using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you start:**\n",
    "- Make sure that you use numpy arrays instead of python lists.\n",
    "- You can assume that all vectors are column vectors not row vectors.\n",
    "- Hint: Try to vectorize as much of your computations as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Implement a loss function which measures the average squared difference between the true data and the model prediction, i.e the mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 1.0 / 1.0**\n",
    "> Correct. But probably the shortest solution is: `((y - prediction) ** 2).mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will make use of numpy to vectorize most of the computations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(y, prediction):\n",
    "    \"\"\"\n",
    "    :param y: The true outputs\n",
    "    :param prediction: The predictions of your model\n",
    "    :return: The MSE between the model predictions and the true outputs\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    residual = y-prediction\n",
    "    squared = residual**2\n",
    "    sum_of_squared = np.sum(squared)\n",
    "    result = (1/y.size)*sum_of_squared\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.2\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0,1,2,3,4])\n",
    "b = np.array([1,3,4,7,8])\n",
    "print(loss(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Implement a function which describes a linear relationship between the input and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 0.5 / 0.5**\n",
    "> Very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_model(intercept, slope, x):\n",
    "    \"\"\"\n",
    "    :param intercept: The model intercept\n",
    "    :param slope: The model slope\n",
    "    :return: The model prediction on x\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    prediction = intercept + slope * x;\n",
    "    return prediction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 10 10 10  4]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([5, 3, 2, 1, 0])\n",
    "print(linear_model(a,b, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Given different values for the slope and the intercept of your model. Implement a function which returns those that result in the best fit, i.e. minimizes the difference between the true data and the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 4.0 / 4.0**\n",
    "> correct, but alternatively you could set initially min_los = np.inf (just 1 line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(intercepts, slopes, x, y):\n",
    "    \"\"\"\n",
    "    :param intercepts: A numpy array of different intercepts\n",
    "    :param slopes: A numpy array of different slopes\n",
    "    :param x: The inputs\n",
    "    :param y: The true outputs\n",
    "    :return (intercept, slope): The intercept and slope that result in the best fit\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    ii32 = np.iinfo(np.int32)\n",
    "    min_loss = ii32.max\n",
    "    best_loss = 0\n",
    "    best_intercept = 0 \n",
    "    best_slope = 0\n",
    "    prediction = np.array([])\n",
    "    for slope in slopes:\n",
    "        for intercept in intercepts:\n",
    "            prediction = linear_model(intercept, slope, x)\n",
    "            best_loss = loss(y, prediction)\n",
    "            if(best_loss < min_loss):\n",
    "                min_loss = best_loss\n",
    "                best_intercept = intercept \n",
    "                best_slope = slope\n",
    "    \n",
    "    return (best_intercept, best_slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Fit a linear model over some training data and plot the resulting model using matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 1.5 / 1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use the datasets functionality provided by sklearn to generate some training data\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "\n",
    "# Let's create some training data to fit our model on\n",
    "x_train, y_train = make_regression(n_samples=50, n_features=1, n_informative=1, noise=30.0)\n",
    "y_train = y_train[:, None] #  make y a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the test data on which we want to evaluate our fitted model\n",
    "x_test = np.linspace(start=-4, stop=4, num=20)\n",
    "x_test = x_test[:, None] #  make x_test a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are the different values for the intercept and slope on which we want to perform a gridsearch\n",
    "intercepts = np.linspace(start=-10.0, stop=10.0, num=50)\n",
    "intercepts = intercepts[:, None] #  make intercepts a column vector\n",
    "slopes = np.linspace(start=0.0, stop=100.0, num=50)\n",
    "slopes = slopes[:, None] #  make slopes a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code to fit a linear model on $x_{train}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: fit a linear model on x_train\n",
    "intercept = 0;\n",
    "slope = 0;\n",
    "\n",
    "intercept, slope = grid_search(intercepts, slopes, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the code below to plot the training data together with the fitted linear model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d7128cc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a matplotlib figure for the training data and our fitted linear regression model\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "axes.scatter(x_train, y_train, color='blue', marker='.', alpha=.6, s=2e2, label='Training Data')\n",
    "y_test = linear_model(intercept, slope, x_test)\n",
    "axes.plot(x_test, y_test, color='red', ls='-', label='Linear Model')\n",
    "axes.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Run the code above several times. Each time the generated data will be different. How would you interpret the result? Is the obtained fit good enough? What are disadvantages of the grid search approach and what could be other (better) ways of fitting a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 3.0 / 3.0**\n",
    "> Very well done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we did a little research about the training and testing data, we saw that sklearn.datasets.make_regression method generates data randomly at each time so the linear regression model using grid_search  would have different  results.\n",
    "\n",
    "- The obtained fit maybe is not good enough because there maybe smaller loss using other intercept and slope that is not existing in the grid_search. \n",
    "\n",
    "- Disadvantages of the grid search approach: one the one hand, grid search is a parameter sweep, which is simply an exhaustive searching through a manually specified subset of the hyper parameter space. Since the parameter space may include real-valued or unbounded value spaces for certain parameters, manually set bounds and discretization may be necessary before applying grid search. On the other hand, grid search may suffer from the curse of dimensionality.\n",
    "\n",
    "- Better ways of fitting a linear model : \n",
    "    - Cross-validation: hold out part of the available data (training data) as a test set X_test, y_test.\n",
    "    - Random Search: when the training data are too much we sacrifice the precision to sample parameters from a random distribution (i.e. uniform) for a fixed number of iterations.\n",
    "    - Gradient descent:To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions\n",
    "You should provide a single Jupyter notebook as a solution. The naming should include the assignment number and matriculation IDs of all team members in the following format:\n",
    "**assignment-1_matriculation1_matriculation_2_matriculation3.ipynb** (in case of 3 team members). \n",
    "Make sure to keep the order matriculation1_matriculation_2_matriculation3 the same for all assignments.\n",
    "\n",
    "Please, submit your solution to your tutor (with **[NNIA][assignment-1]** in email subject):\n",
    "1. Maksym Andriushchenko s8mmandr@stud.uni-saarland.de\n",
    "2. Marius Mosbach s9msmosb@stud.uni-saarland.de\n",
    "3. Rajarshi Biswas rbisw17@gmail.com\n",
    "\n",
    "**If you are in a team, please submit only 1 solution to only 1 tutor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simply loss: 1.1875, loss after GS: 1.0, w=-1, b=1\n"
     ]
    }
   ],
   "source": [
    "# Maksym offers a simple way to check correctness of the solution (basically, unit-test)\n",
    "# This doesn't mean that we shouldn't inspect the student's code line-by-line!\n",
    "# Expected: simply loss: 1.1875, loss after GS: 1.0, w=-1, b=1\n",
    "\n",
    "import numpy as np\n",
    "flag_2d = False\n",
    "x = np.array([2,3,4,5])\n",
    "y = np.array([1, 2, 3, 6])\n",
    "intercepts = np.array([-2, -1, 0, 1, 2])\n",
    "slopes = np.array([-2, -1, 0, 1, 2])\n",
    "if flag_2d:\n",
    "    x, y, intercepts, slopes = x[:, None], y[:, None], intercepts[:, None], slopes[:, None]\n",
    "intercept, slope = grid_search(intercepts, slopes, x, y)\n",
    "y_pred = linear_model(intercept, slope, x)\n",
    "print('simply loss: {}, loss after GS: {}, w={}, b={}'.format(loss(y, np.array([1.5, 2.5, 3.5, 4])), loss(y, y_pred), intercept, slope))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
