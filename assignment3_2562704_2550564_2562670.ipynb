{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment sheet 3: Numerical Computation and Prinicipal Component Analysis (Deadline: Nov 24, 23:59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set notebook to full width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Issues with Softmax $~$ (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture you were introduced to the softmax function which is used to generate probabilities corresponding to the output labels. Typically, the input to the softmax function is a vector of numerical values over the labels and the output is a vector(of same dimension as the input vector) of corresponding probabilities.\n",
    "**Softmax function is given by,** $~$\n",
    "$$Softmax(x)_i = \\frac{exp(x_i)}{\\sum_{j=1}^n exp(x_j)}$$\n",
    "\n",
    "**Numerical issues might occur when computing softmax functions on a computer which can perform computations\n",
    "only upto a certain precision.** [Suggested reading $-$ [chapter 4.1 of DeepLearningBook](http://www.deeplearningbook.org/contents/numerical.html)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$. Name these numerical issues and explain them. ($1$ points)\n",
    "\n",
    "Numerical issues might happen when we are dealing with too small or too big numbers since we need to represent infinitely many real numbers with a finite number of bit patterns.\n",
    "One issue is underflow; it occurs when numbers near zero are rounded to zero.\n",
    "The other one is overflow; it occurs when numbers with large magnitude are approximated as $\\infty$ or $-\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. Suggest a remedy (with explanation on why it works) to overcome these numerical issues occuring with Softmax computation. Prove that this remedy actually does not change the softmax criteria. Describe a situation where the proposed remedy still fails to remove instability. ($1$ point)\n",
    "\n",
    "These difficulties can be resolved by instead evaluating $softmax(z)$ where $ z = x - max_ix_i$. Since we only add or subtract a scalar from the input vector, the result is not effected.\n",
    "\n",
    "Shortly we will represent the maximum element of vector $x$ with $max$ then; \n",
    "$$ \\frac{exp(x_i - max)}{\\sum_{j=1}^n exp(x_j - max)}$$    \n",
    "\n",
    "$$ \\frac{exp(x_i)exp(-max)}{\\sum_{j=1}^n [exp(x_j) exp(-max)]}$$\n",
    "\n",
    "$$ \\frac{exp(x_i)exp(-max)}{(\\sum_{j=1}^n exp(x_j)) exp(-max)} = \\frac{exp(x_i)}{\\sum_{j=1}^n exp(x_j)}$$\n",
    "\n",
    "However the error still can occur if we implement log softmax(x) by first running the softmax subroutine then passing the result to the log function, we could erroneously obtain $-\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. First write a naive Softmax implementation, in numpy, that can produce numerical instability. Then write a modified Softmax implementation which is numerically stable.  ($0.5 + 0.5 = 1$ points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5 10 15 20 25 30 35 40 45 50 55]\n",
      "[  1.29082491e-24   1.91575403e-22   2.84323108e-20   4.21972907e-18\n",
      "   6.26263322e-16   9.29457180e-14   1.37943676e-11   2.04726568e-09\n",
      "   3.03841167e-07   4.50940274e-05   6.69254707e-03   9.93262053e-01]\n",
      "[  1.29082491e-24   1.91575403e-22   2.84323108e-20   4.21972907e-18\n",
      "   6.26263322e-16   9.29457180e-14   1.37943676e-11   2.04726568e-09\n",
      "   3.03841167e-07   4.50940274e-05   6.69254707e-03   9.93262053e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO : Define inputs\n",
    "inputs = np.arange(0,60,5)\n",
    "print (inputs)\n",
    "\n",
    "def softmax_naive(inputs):\n",
    "    exp_array = np.exp(inputs)\n",
    "    return (exp_array/(np.sum(exp_array)))\n",
    "\n",
    "def softmax_modified(inputs):\n",
    "    z = inputs - np.amax(inputs) \n",
    "    exp_array = np.exp(z)\n",
    "    return (exp_array/(np.sum(exp_array)))\n",
    "\n",
    "print (softmax_naive(inputs))\n",
    "print (softmax_modified(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis $~$ (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4$. Is PCA supervised or unsupervised, logically explain your answer. Which is the tunable parameter in PCA?\n",
    "Briefly explain the role of this parameter in PCA.  ($1+0.5+0.5 = 2$ points)\n",
    "\n",
    " 1) Unsupervised,PCA helps in producing low dimensional representation of the dataset by identifying a set of linear combination of features which have maximum variance and are mutually un-correlated. This linear dimensionality technique could be helpful in understanding latent interaction between the variable in an unsupervised setting. In a supervised setting such as Classification or Regression, one observes both a set of input variables(X1, .. Xn ) and response or output variables (Y). However, in un-supervised setting the goal is to identify “meaningful” informative patterns in the given data. There is no corresponding output Y of each input X here in PCA. \n",
    "\n",
    " 2) Tunable parameter is what we want to reduce the dimension to,here in this Task 4, we reduce dimensions from 2 to 1. \n",
    "\n",
    " 3) The encoding formula,  $f(x)=D^Tx$, D contains the eigenvectors corresponding to the larger eigenvalues of $X^TX$, so the column of D represents the degree of matrix after reducing dimensions.In PCA, the eigendecomposition is to tune this parameter, we want to use lower dimensions of data to represents the oringinal one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5$. Consider the following data:\n",
    "\n",
    "setA: ${\\bf x}^{(1)}$=$(2, 4)^T$, ${\\bf x}^{(2)}$=$(2, 2)^T$, ${\\bf x}^{(3)}$=$(3, 1)^T$, ${\\bf x}^{(4)}$=$(5, 1)^T$ \n",
    "\n",
    "setB: ${\\bf x}^{(1)}$=$(-1, 1)^T$, ${\\bf x}^{(2)}$=$(-2, 2)^T$, ${\\bf x}^{(3)}$=$(-1, 3)^T$, ${\\bf x}^{(4)}$=$(-1, 4)^T$\n",
    "\n",
    "$(a)$ Compress the above sets of vectors into a one-dimensional set using PCA, i.e., derive the encoder function $f(x)=D^{T}x$ as defined in the lecture. Then apply f to the datasets inorder to compress them. ($1.5 + 1.5$ points)\n",
    "\n",
    "$\\mathbf{SetA}=\\left[\\begin{array}{cccc}\n",
    "   2 & 4\\\\\n",
    "   2 & 2\\\\\n",
    "   3 & 1\\\\\n",
    "   5 & 1\\\\\n",
    "  \\end{array}\\right]$   ,    Mean of vectors in Set A: $\\mathbf{MeanA}=\\left[\\begin{array}{cccc}\n",
    "   3 & 2\\\\ \n",
    "  \\end{array}\\right]$\n",
    "  Remove mean, $\\mathbf{X}=\\left[\\begin{array}{cccc}\n",
    "   -1 & 2\\\\\n",
    "   -1 & 0\\\\\n",
    "   0 & -1\\\\\n",
    "   2 & 1\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "  $\\mathbf{x=X^T}=\\left[\\begin{array}{cccc}\n",
    "   -1 & -1 & 0 & 2\\\\\n",
    "   2 & 0 & -1 & -1\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "  \n",
    "  $$\\mathbf{X^TX}=\\left[\\begin{array}{cccc}\n",
    "   6 & -4\\\\\n",
    "  -4 &  6\\\\\n",
    "  \\end{array}\\right] $$Make Eigendecomposition of $X^TX$,\n",
    " let $|X^TX-\\lambda I|=0$\n",
    " The larger eigenvalue is:$\\lambda_1=10$\n",
    " \n",
    " From $|X^TX-10I|=0$, we have D containing the eigenvectors corresponding to the largest eigenvalues of $X^TX$,\n",
    "  $\\mathbf{D_1}=\\left[\\begin{array}{cccc}\n",
    "   \\frac{\\sqrt{2}}{2}\\\\\n",
    "  \\frac{\\sqrt{2}}{-2}\n",
    "  \\end{array}\\right]$ \n",
    "\n",
    "Now we encode the data,$\\mathbf{D_1^Tx}=\\left[\\begin{array}{cccc}\n",
    "   \\frac{-3\\sqrt{2}}{2} &\n",
    "   \\frac{\\sqrt{2}}{-2}  &\n",
    "   \\frac{\\sqrt{2}}{2}   &\n",
    "   \\frac{3\\sqrt{2}}{2}\\\\\n",
    "  \\end{array}\\right]$ \n",
    "\n",
    "As to $\\mathbf{SetB}=\\left[\\begin{array}{cccc}\n",
    "   -1 & 1\\\\\n",
    "   -2 & 2\\\\\n",
    "   -1 & 3\\\\\n",
    "   -1 & 4\\\\\n",
    "  \\end{array}\\right]$,\n",
    "following the same steps, we have $\\mathbf{Y}=\\left[\\begin{array}{cccc}\n",
    "   0.25 & -1.5\\\\\n",
    "   -0.75 & 0.5\\\\\n",
    "   0.25 & 0.5\\\\\n",
    "   0.25 & 1.5\\\\\n",
    "  \\end{array}\\right]$ , as to Y,\n",
    "the larger eigenvalue is $\\lambda_2=5.058$,\n",
    "  $\\mathbf{D_2}=\\left[\\begin{array}{cccc}\n",
    "   0.1153\\\\\n",
    "   0.9933\\\\\n",
    "  \\end{array}\\right]$ \n",
    "  Now we encode the data,$\\mathbf{D_2^Ty}=\\left[\\begin{array}{cccc}\n",
    "   -1.4611 &-0.5831 & 0.5255 & 1.5188\n",
    "   \\\\\n",
    "  \\end{array}\\right]$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$. For both the above sets sketch the corresponding datasets in a separate figure. \n",
    "Also include the reconstructed vectors into the corresponding figures. ($2$ points)\n",
    "\n",
    "$ reconstructed vector_1=D_1D_1^Tx=\\left[\\begin{array}{cccc}\n",
    "   -1.5 & -.5 & 0.5 & 1.5\\\\\n",
    "   1.5 & 0.5 &-.5 & -1.5\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "$ reconstructed vector_2=D_2D_2^Ty=\\left[\\begin{array}{cccc}\n",
    "   -0.1685 & -0.0672 & 0.0606 & 0.1751\\\\\n",
    "   -1.4513 & -0.5792 & 0.5220 & 1.5083\\\\\n",
    "  \\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQC6v8D9+bOZuxpZQYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107559a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108509d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1=np.array([-1,-1,0,2])\n",
    "y1=np.array([2,0,-1,-1])\n",
    "\n",
    "x1_rec=np.array([-1.5,-0.5,0.5,1.5])\n",
    "y1_rec=np.array([1.5,0.5,-0.5,-1.5])\n",
    "\n",
    "\n",
    "plt.scatter(x1, y1)\n",
    "plt.scatter(x1_rec, y1_rec)\n",
    "\n",
    "plt.legend(['original of set A', 'reconstructed of set A'], loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "x2=np.array([0.25,-0.75,0.25,0.25])\n",
    "y2=np.array([-1.5,-0.5,0.5,-1.5])\n",
    "\n",
    "x2_rec=np.array([-0.1685,-0.0672,0.0606,0.1751])\n",
    "y2_rec=np.array([-1.4513,-0.5792,0.5220,1.5086])\n",
    "\n",
    "\n",
    "plt.scatter(x2, y2)\n",
    "plt.scatter(x2_rec, y2_rec)\n",
    "\n",
    "plt.legend(['original of set B', 'reconstructed of set B'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent and Newton's method $~$ (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose $f(x) = 2x^3 - 5x + 6$ **\n",
    "\n",
    "$6$. Write down the mathematical expressions for minimizing f(x) using Gradient descent(GD) and then using Newton's Method(NM). ($1$ points)\n",
    "\n",
    "- Gradient descent : $x' = x - \\epsilon \\nabla_x f(x)$ where $x'$ is the updated point, $\\nabla_x f(x)$ is the gradient of $f$ and $\\epsilon$ is the learning rate, a positive scalar determining the size of the step.\n",
    "    For the above function $\\nabla_x f(x) = 6x^2 - 5$ therefore $x' = x - \\epsilon (6x^2 - 5)$.\n",
    "- Newton's Method : $x' = x - H(f)(x)^{-1} \\nabla_x f(x)$ where $ H(f)(x) $ Hessian matrix of $f$. \n",
    "    Since we have only one variable in the function the Hessian is $ H(f)(x) = f''(x) $ therefore $x' = x - (12x)^{-1} (6x^2 -5)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$7$. Report the updated values of x, both for GD and NM, at $x = 0$. what do you observe? ($1$ points)\n",
    "\n",
    "- GD: $\\nabla_x f(x) = 6x^2 - 5$ at $x = 0$;  $\\nabla_x f(0) = - 5$ \n",
    "\n",
    "    $x' = 0 - \\epsilon \\nabla_x f(0)$ therefore the updated value $x' = 5\\epsilon $\n",
    "    assuming $\\epsilon = 0.01 $ then we have $x' = 0.05$\n",
    "    \n",
    "- NM: $ H(f)(x)_{i,j} = \\frac{\\partial^2} {\\partial x_i \\partial x_j} \\rightarrow  H(f)(x) = [12x] $ \n",
    "     \n",
    "    $x' = x - (12x)^{-1} (6x^2 -5)$ for $x = 0$ we have $x' = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$8$. Perform GD and NM for the above function using Tensorflow. ($1.5 + 1.5$ points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "fx = 2*x**3 - 5*x + 6\n",
    "dfx = tf.gradients(fx, x)[0]\n",
    "eps = 0.01\n",
    "x_upd = x - eps*dfx\n",
    "x_upd_out = sess.run(x_upd, feed_dict = {x: 0.0})\n",
    "\n",
    "print (x_upd_out)\n",
    "# TODO : Implement Gradient Descent with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "fx = 2*x**3 - 5*x + 6\n",
    "dfx = tf.gradients(fx, x)[0]\n",
    "ddfx = tf.gradients(dfx, x)[0]\n",
    "x_upd = x - dfx*(ddfx)**(-1)\n",
    "x_upd_out = sess.run(x_upd, feed_dict = {x: 0.0})\n",
    "\n",
    "print (x_upd_out)\n",
    "# TODO : Implement Newton's Method with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent computation and visualisation $~$ (3 + 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now visualize the Gradient Descent algorithm to fit a straight line to data generated using  $y = \\theta_{true}x$ $~$, i.e., use this expression to first produce the data (see code below the lines starting with m=20 and following) and then try to fit a straight line to this data. Fitting a straight line means that you have to approximate this $\\theta_{true}$ parameter using the hypothesis or predictive model by minimizing the cost function defined below.\n",
    "\n",
    "**For this task you should minimize a cost function of the form:**\n",
    "$$\\frac{1}{2m}\\sum_{i=1}^m [h_{\\theta}(x^i)-y^i]^2$$\n",
    "where\n",
    "- $x^i$ is the $i^{th}$ input \n",
    "\n",
    "- $y^i$ is the true $i^{th}$ response or output\n",
    "\n",
    "- $h_{\\theta}(x)$ is the hypothesis or predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assume $~$ $h_{\\theta}(x) = \\theta x$ $~$ to be the hypothesis or predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114a29278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the true data which is to be fitted\n",
    "m = 20                      # number of data points for x\n",
    "theta_true = 0.5            # corresponds to the true slope\n",
    "x = np.linspace(-1,1,m)     # x values or inputsm\n",
    "y = theta_true * x          # True response\n",
    "\n",
    "# Create a subplot window\n",
    "# On the left window plot the true data and the approximation that you obtain with different estimates of the slope theta_true\n",
    "# on the right window plot the cost function \n",
    "# TODO : Create the subplot window\n",
    "\n",
    "def hypothesis(x, theta):\n",
    "    \"\"\"Our \"hypothesis or predictive model\", a straight line through the origin.\"\"\"\n",
    "    return x*theta\n",
    "\n",
    "def cost_func(theta):\n",
    "    \"\"\"The cost function describing the goodness of fit.\"\"\"  \n",
    "    y_hypo = hypothesis(x, theta)\n",
    "    return (1/2*m)* np.sum((y_hypo-y)**2)\n",
    "\n",
    "\n",
    "# First construct a grid of theta parameter and their corresponding\n",
    "# cost function values.\n",
    "theta_grid = np.linspace(-0.2,1,50)\n",
    "\n",
    "cost_values = [cost_func(i) for i in theta_grid]\n",
    "J_grid = np.matrix([theta_grid, cost_values])\n",
    "\n",
    "# Find the cost function values to be stored in J_grid\n",
    "# TODO : Create J_grid\n",
    "\n",
    "\n",
    "# Plot the cost function as a function of theta.\n",
    "# TODO : Do the plot\n",
    "theta1=0.7\n",
    "y_theta1=theta1 * x \n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,y_theta1)\n",
    "plt.subplot(122)\n",
    "plt.plot(theta_grid, cost_values)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Take N steps with learning rate alpha down the steepest gradient,\n",
    "# starting at theta = 0.\n",
    "N = 10\n",
    "alpha = 1 \n",
    "\n",
    "#try also 0.02 to see what happens\n",
    "\n",
    "# this is just a starting value of alpha, \n",
    "# you must consider different values of alpha (try using large values)\n",
    "# and redo the steps below to generate different plots\n",
    "theta = [0]\n",
    "\n",
    "\n",
    "\n",
    "# TODO :Compute the N steps down the steepest gradient\n",
    "\n",
    "# TODO : Annotate the cost function plot with coloured points indicating the\n",
    "# parameters chosen and red arrows indicating the steps down the gradient.\n",
    "# Also plot the fit function on the left window of the subplot in a matching colour.\n",
    "\n",
    "# TODO : Put the labels, titles and a legend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now assume that the data is generated using  $y = \\theta_1x + \\theta_0$\n",
    "** Following the same logic you applied for the above task define a predictive model \n",
    "and perform 5 steps of gradient descent with learning rate alpha = 0.7 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the true data which is to be fitted\n",
    "m = 20\n",
    "theta0_true = 2\n",
    "theta1_true = 0.5\n",
    "x = np.linspace(-1,1,m)\n",
    "y = theta0_true + theta1_true * x\n",
    "\n",
    "# Create the sub-plot: left window is the data, right window will be the cost function.\n",
    "# TODO\n",
    "\n",
    "\n",
    "def hypothesis(x, theta0, theta1):\n",
    "    \"\"\"Our \"hypothesis function\", a straight line.\"\"\"\n",
    "    \n",
    "    # TODO : Implement\n",
    "    pass\n",
    "\n",
    "def cost_func(theta0, theta1):\n",
    "    \"\"\"The cost function, J(theta0, theta1) describing the goodness of fit.\"\"\"\n",
    "    \n",
    "    # TODO : Implement\n",
    "    pass\n",
    "\n",
    "\n",
    "# First construct a grid of (theta0, theta1) parameter pairs and their\n",
    "# corresponding cost function values.\n",
    "theta0_grid = np.linspace(-1,4,101)\n",
    "theta1_grid = np.linspace(-5,5,101)\n",
    "\n",
    "# TODO : Compute the cost function values\n",
    "\n",
    "\n",
    "# TODO : Do a labeled contour plot for the cost function on right window of the above subplot\n",
    "\n",
    "\n",
    "# TODO : Take 5 steps with learning rate alpha = 0.7 down the steepest gradient,\n",
    "# starting at (theta0, theta1) = (0, 0).\n",
    "\n",
    "\n",
    "# TODO : Annotate the cost function plot with coloured points indicating the\n",
    "# parameters chosen and red arrows indicating the steps down the gradient.\n",
    "# Also plot the fit function on the left window in a matching colour.\n",
    "\n",
    "\n",
    "# TODO : Add the labels, titles and a legend to the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra Bonus\n",
    "- [Additional material - Linear Algebra Basics](http://www.cs.ubc.ca/~schmidtm/Documents/2009_Notes_LinearAlgebra.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace of a Matrix $~$ (3 points)\n",
    "- [Reading material on Trace](https://en.wikipedia.org/wiki/Trace_(linear_algebra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prove that the trace of a ***symmetric positive definite*** matrix is the sum of its eigenvalues.    ($0.5$ points)\n",
    "\n",
    "- The trace operator gives the sum of all of the diagonal entries of a matrix: \n",
    "$$Tr(A)=\\sum_i{A_{i,j}}$$\n",
    "if we choose any orthonormal basis $v_1,…,v_n$ for $\\mathbb{R_n}$ (with respect to the standard inner product $\\langle\\cdot,\\cdot\\rangle$) then\n",
    "$$Tr(A)=\\sum_i{\\langle Av_i,v_i\\rangle}$$\n",
    "\n",
    "If A is symmetric, then by choosing $v_1,…,v_n$ to be an orthonormal basis of eigenvectors of $A$ (with $Avi=\\lambda_iv_i$), we immediately get\n",
    "\n",
    "$$Tr(A)=\\sum_i{\\langle Av_i,v_i\\rangle} = \\sum_i{\\langle \\lambda_iv_i,v_i\\rangle} = \\sum_i{\\lambda_i} $$\n",
    "\n",
    "Suppose $\\mathbf{Y}$ is a $m \\times n$ matrix with $m \\leq n$ and has ***full rank***, then:\n",
    "\n",
    "\n",
    "\n",
    "$(a)$.   Give the rank of $\\mathbf{Y}$.                                                                 ($0.5$ points)\n",
    "\n",
    "rank($\\mathbf{Y}$) = m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$.  Show that trace of $\\mathbf{Y}^{T}(\\mathbf{Y}^T\\mathbf{Y})^{-1}\\mathbf{Y}$ = rank($\\mathbf{Y}$)                                     ($1$ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(c)$. Prove that $\\mathbf{Y}^{T}(\\mathbf{Y}^T\\mathbf{Y})^{-1}\\mathbf{Y}$ is the projection matrix w.r.t space defined by $\\mathbf{Y}$.     ($1$ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacobian $~$ (3 points)\n",
    "\n",
    "***[Reading material on Jacobian](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the Jacobian determinant of $\\frac{\\partial(fg, h)}{\\partial(u, v)}$ is equal to $\\frac{\\partial(f, h)}{\\partial(u, v)}g + f\\frac{\\partial(g, h)}{\\partial(u, v)}$,\n",
    "\n",
    "where $f$,$g$, and $h$ are functions of $u$ and $v$ (i.e., $f(u,v)$, $g(u,v)$, and $h(u,v)$)   ($3$ points)\n",
    "\n",
    "Hint: Use the property $\\frac{\\partial(y, x)}{\\partial(u, v)} = \\frac{\\partial(y)}{\\partial(u)}\\frac{\\partial(x)}{\\partial(v)}-\\frac{\\partial(y)}{\\partial(v)}\\frac{\\partial(x)}{\\partial(u)}$\n",
    "\n",
    "\n",
    "Direct calculation leads to:\n",
    " $\\frac{\\partial(fg, h)}{\\partial(u, v)}$=$\\frac{\\partial(fg)}{\\partial(u)}$$\\frac{\\partial(h)}{\\partial(v)}$-$\\frac{\\partial(fg)}{\\partial(v)}$ $\\frac{\\partial(h)}{\\partial(u)}$=($\\frac{\\partial(f)}{\\partial(u)}g$+$\\frac{\\partial(g)}{\\partial(u)}f)$$\\frac{\\partial(h)}{\\partial(v)}$-($\\frac{\\partial(f)}{\\partial(v)}g$+$\\frac{\\partial(g)}{\\partial(v)}f)$$\\frac{\\partial(h)}{\\partial(u)}$=($\\frac{\\partial(f)}{\\partial(u)}$$\\frac{\\partial(h)}{\\partial(v)}$-$\\frac{\\partial(f)}{\\partial(v)}$$\\frac{\\partial(h)}{\\partial(u)}$)g+($\\frac{\\partial(g)}{\\partial(u)}$$\\frac{\\partial(h)}{\\partial(v)}$-$\\frac{\\partial(g)}{\\partial(v)}$$\\frac{\\partial(h)}{\\partial(u)}$)f=$\\frac{\\partial(f, h)}{\\partial(u, v)}g + f\\frac{\\partial(g, h)}{\\partial(u, v)}$\n",
    " \n",
    " \n",
    " Proved\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hessian $~$ (2 points)\n",
    "***[Reading material on Hessian](https://en.wikipedia.org/wiki/Hessian_matrix)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{M}=\\left[\\begin{array}{cccc}\n",
    "   5 & 1 & 0 & 1\\\\\n",
    "   1 & 4 & 1 & 0\\\\\n",
    "   0 & 1 & 3 & 1\\\\\n",
    "   1 & 0 & 1 & 2\\\\\n",
    "  \\end{array}\\right]$\n",
    "  \n",
    "denote the Hessian matrix at particular point for a particular function.\n",
    "\n",
    "$(a)$. What properties of the functional can you infer from the above information.(give mathematical reasons) ($1$ point)\n",
    "\n",
    "Set $|M-\\lambda I|=0$\n",
    "The eingenvalues are $1, 3, 4 ,6 $ which are pisitive values, so M is positive defined. It means at this particular point, it is a local minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$. Provide a generic mathematical representation (e.g. the generic representation of a straight line is $ax+by+c=0$) for the above function. ($1$ point)\n",
    "$ \\frac{5}{2}x_1^2+x_1x_2+x_1x_4+2x_2^2+x_2x_3+x_3x_4+x_4^2+\\frac{3x_3^2 }{2}+c=0$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
